{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5652ce4c-c75d-4484-a43a-31ffcf7a2b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Geospatial\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "import zarr # Not referenced, but required for xarray\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import fsspec\n",
    "import pystac\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import zipfile\n",
    "from itertools import cycle\n",
    "\n",
    "# Path to data folder with provided material\n",
    "data_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ef421-3dea-4894-a605-d1695657335b",
   "metadata": {},
   "source": [
    "## Response Variable\n",
    "\n",
    "Before we can build our model, we need to load in the frog occurrences data and generate our response variable. To do this, we first need to unzip the training data and store it on our machine. Then we can write a function that abstracts the loading process, with the option of providing a bounding box to only take those occurrences within a region of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf305264-0afd-40c3-a9b1-3b782593ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists(data_path+'training_data/'):\n",
    " #   os.mkdir(data_path+'training_data/')\n",
    "  #  with zipfile.ZipFile(data_path+'GBIF_training_data.zip', 'r') as zip_ref:\n",
    "   #     zip_ref.extractall(data_path+'training_data/')\n",
    "        \n",
    "def filter_bbox(frogs, bbox):\n",
    "    frogs = frogs[lambda x: \n",
    "        (x.decimalLongitude >= bbox[0]) &\n",
    "        (x.decimalLatitude >= bbox[1]) &\n",
    "        (x.decimalLongitude <= bbox[2]) &\n",
    "        (x.decimalLatitude <= bbox[3])\n",
    "    ]\n",
    "    return frogs\n",
    "\n",
    "def get_frogs(file, year_range=None, bbox=None):\n",
    "    \"\"\"Returns the dataframe of all frog occurrences for the bounding box specified.\"\"\"\n",
    "    columns = [\n",
    "        'gbifID','eventDate','country','continent','stateProvince',\n",
    "        'decimalLatitude','decimalLongitude','species'\n",
    "    ]\n",
    "    country_names = {\n",
    "        'AU':'Australia', 'CR':'Costa Rica', 'ZA':'South Africa','MX':'Mexico','HN':'Honduras',\n",
    "        'MZ':'Mozambique','BW':'Botswana','MW':'Malawi','CO':'Colombia','PA':'Panama','NI':'Nicaragua',\n",
    "        'BZ':'Belize','ZW':'Zimbabwe','SZ':'Eswatini','ZM':'Zambia','GT':'Guatemala','LS':'Lesotho',\n",
    "        'SV':'El Salvador', 'AO':'Angola', np.nan:'unknown or invalid'\n",
    "    }\n",
    "    continent_names = {\n",
    "        'AU':'Australia', 'CR':'Central America', 'ZA':'Africa','MX':'Central America','HN':'Central America',\n",
    "        'MZ':'Africa','BW':'Africa','MW':'Africa','CO':'Central America','PA':'Central America',\n",
    "        'NI':'Central America','BZ':'Central America','ZW':'Africa','SZ':'Africa','ZM':'Africa',\n",
    "        'GT':'Central America','LS':'Africa','SV':'Central America','AO':'Africa', np.nan:'unknown or invalid' \n",
    "    }\n",
    "    frogs = (\n",
    "        pd.read_csv('occurrence.txt', sep='\\t', parse_dates=['eventDate'])\n",
    "        .assign(\n",
    "            country =  lambda x: x.countryCode.map(country_names),\n",
    "            continent =  lambda x: x.countryCode.map(continent_names),\n",
    "            species = lambda x: x.species.str.title()\n",
    "        )\n",
    "        [columns]\n",
    "    )\n",
    "    if year_range is not None:\n",
    "        frogs = frogs[lambda x: \n",
    "            (x.eventDate.dt.year >= year_range[0]) & \n",
    "            (x.eventDate.dt.year <= year_range[1])\n",
    "        ]\n",
    "    if bbox is not None:\n",
    "        frogs = filter_bbox(frogs, bbox)\n",
    "    return frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47010498-24fb-42b1-8ccc-3f7f89235c59",
   "metadata": {},
   "source": [
    "### Sub-sampling\n",
    "\n",
    "For this demonstration, we will constrain our search to frogs in the Greater Sydney area found between the start of 2015 to the end of 2019. This gives a varied landscape of bushland, plains, rivers, and urban areas. This is done by providing `year_range` and `bbox` parameters to the get_frogs function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d75a397-ae04-48ae-89bd-406a209be3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounding box for Test Region 5\n",
    "\n",
    "min_lon5, min_lat5 = (115.7, -32.5)  # Lower-left corner\n",
    "max_lon5, max_lat5 = (116.7, -31.5)  # Upper-right corner\n",
    "bbox5 = (min_lon5, min_lat5, max_lon5, max_lat5)\n",
    "\n",
    "# Load in data\n",
    "#all_frog_data = get_frogs(data_path+'/training_data/occurrence.txt', year_range=(2015, 2019), bbox=bbox)\n",
    "boxes = [bbox5]\n",
    "#all_frog_data = get_frogs('occurrence.txt', year_range=(2015, 2019), bbox=bbox)\n",
    "#all_frog_data[('species'=='Litoria Fallax')]\n",
    "\n",
    "#get_frogs('occurrence.txt', year_range=(2015, 2019), bbox=i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4236-b9a9-4622-9a59-2a3365ae9a01",
   "metadata": {},
   "source": [
    "## Predictor Variables\n",
    "\n",
    "Now that we have our response variable, it is time to gather the predictor variables from the TerraClimate dataset. For a more in-depth look at the TerraClimate dataset and how to query it, see the [TerraClimate supplementary notebook](./supplementary_notebooks/TerraClimate.ipynb)\n",
    "\n",
    "### Accessing the TerraClimate Data\n",
    "\n",
    "To get the TerraClimate data, we write a function called `get_terraclimate`. This function will fetch all data intersecting with the bounding box and will calculate various metrics over the time dimension for each coordinate. In this example, we will take four metrics from four assets, namely the mean maximum monthly air temp (`tmax_mean`), mean minimum monthly air temp (`tmin_mean`), mean accumulated precipitation (`ppt_mean`) and mean soil moisture (`soil_mean`), all calculated over a five year timeframe from the start of 2015 to the end of 2019.\n",
    "\n",
    "To assist in visualisations, this function has an interpolation functionality which will allow the comparitively coarse temporal resolution of the terraclimate data to be mapped to a larger set of coordinates, creating an ($n$ x $m$) image. We will choose (512 x 512).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895f4351-847a-4c66-a764-f9a0888b9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, metrics, time_slice=None, assets=None, features=None, interp_dims=None, verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area, allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e65acf-b700-43a3-9c39-d0f40a87e616",
   "metadata": {},
   "source": [
    "Below, we define the products to take from TerraClimate in `assets` and the metrics to calculate from them in `tc_metrics`. Each metric is applied to each asset, so to pick the desired asset/metric pairs we define a list of strings in the form '\\<asset\\>_\\<metric\\>' in `features`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26999ce2",
   "metadata": {},
   "source": [
    "Reference evapotranspiration (ASCE Penman-Montieth), Runoff, Actual Evapotranspiration, Climate Water Deficit, Soil Moisture, Snow Water Equivalent, Palmer Drought Severity Index, Vapor pressure deficit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7da9ea-10ed-418e-a803-ea4db74e0c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tmax_mean', 'tmin_mean', 'ppt_mean', 'srad_mean', 'vap_mean',\n",
       "       'aet_mean', 'pet_mean'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics to measure over time dimension\n",
    "tc_metrics = {\n",
    "    'mean':{\n",
    "        'fn':np.nanmean,\n",
    "        'params':{}\n",
    "    },\n",
    "    'min':{\n",
    "        'fn':np.nanmin,\n",
    "        'params':{}\n",
    "    },\n",
    "    'max':{\n",
    "        'fn':np.nanmax,\n",
    "        'params':{}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Date range to take\n",
    "time_slice = ('2015-01-01','2020-12-31')\n",
    "\n",
    "# Measurements to take: primary + secondary variables\n",
    "assets=['tmax', 'tmin', 'ppt', 'srad','vap','aet','pet']\n",
    "\n",
    "# Features to take, in form '<asset>_<metric>'\n",
    "features=['tmax_mean', 'tmin_mean', 'ppt_mean','srad_mean','vap_mean','aet_mean','pet_mean']\n",
    "\n",
    "# Interpolate values to a 512x512 image\n",
    "interp_dims = (512, 512)\n",
    "\n",
    "#weather_data = get_terraclimate(bbox5, tc_metrics, time_slice=time_slice, assets=assets, features=features, interp_dims=interp_dims)\n",
    "weather_data = xr.open_dataset('weather_data_testRegion5.nc')\n",
    "display(weather_data.band.values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ec1c861",
   "metadata": {},
   "source": [
    "weather_data.to_netcdf('weather_data_testRegion5.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06fc558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These stuff combines the lat& longs of the test region, and the weather_data, into a dictionary\n",
    "test_file = pd.read_csv('challenge_1_submission_template.csv')\n",
    "test_regions = [{'title': 4, 'bbox': (115.7, -32.5, 116.7, -31.5)}]\n",
    "for region in test_regions:\n",
    "    region['coords'] = filter_bbox(test_file[['id', 'decimalLongitude', 'decimalLatitude']], region['bbox'])\n",
    "    region['predictors'] = weather_data\n",
    "    #get_terraclimate(region['bbox'], tc_metrics, time_slice=time_slice, assets=assets, features=features)\n",
    "    #region['result'] = predict_frogs(region['predictors'], clf2) > 0.5\n",
    "    #region['result'].plot.imshow(x='x', y='y', vmin=0, vmax=1)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52621be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'bbox', 'coords', 'predictors'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f530ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_coords = region['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a567268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no 'key' in weather data (as in frog_data), we need to manually assign\n",
    "region_coords = (region_coords.reset_index(drop=True).assign(key=lambda x: x.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cce1b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3453</td>\n",
       "      <td>115.886000</td>\n",
       "      <td>-31.936300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3454</td>\n",
       "      <td>115.887000</td>\n",
       "      <td>-31.936500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3455</td>\n",
       "      <td>115.885000</td>\n",
       "      <td>-31.938400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3456</td>\n",
       "      <td>115.883000</td>\n",
       "      <td>-31.940300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3457</td>\n",
       "      <td>115.858000</td>\n",
       "      <td>-32.046300</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>4046</td>\n",
       "      <td>116.150192</td>\n",
       "      <td>-31.884385</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>4047</td>\n",
       "      <td>115.779737</td>\n",
       "      <td>-32.412962</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4048</td>\n",
       "      <td>115.856628</td>\n",
       "      <td>-32.147959</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4049</td>\n",
       "      <td>116.238000</td>\n",
       "      <td>-31.827000</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>4050</td>\n",
       "      <td>116.073031</td>\n",
       "      <td>-31.582511</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  decimalLongitude  decimalLatitude  key\n",
       "0    3453        115.886000       -31.936300    0\n",
       "1    3454        115.887000       -31.936500    1\n",
       "2    3455        115.885000       -31.938400    2\n",
       "3    3456        115.883000       -31.940300    3\n",
       "4    3457        115.858000       -32.046300    4\n",
       "..    ...               ...              ...  ...\n",
       "593  4046        116.150192       -31.884385  593\n",
       "594  4047        115.779737       -32.412962  594\n",
       "595  4048        115.856628       -32.147959  595\n",
       "596  4049        116.238000       -31.827000  596\n",
       "597  4050        116.073031       -31.582511  597\n",
       "\n",
       "[598 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8208c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>key</th>\n",
       "      <th>aet_mean</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>ppt_mean</th>\n",
       "      <th>srad_mean</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmin_mean</th>\n",
       "      <th>vap_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3453</td>\n",
       "      <td>115.886</td>\n",
       "      <td>-31.9363</td>\n",
       "      <td>0</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>140.916672</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>234.066666</td>\n",
       "      <td>24.546669</td>\n",
       "      <td>13.283335</td>\n",
       "      <td>1.3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3454</td>\n",
       "      <td>115.887</td>\n",
       "      <td>-31.9365</td>\n",
       "      <td>1</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>140.916672</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>234.066666</td>\n",
       "      <td>24.546669</td>\n",
       "      <td>13.283335</td>\n",
       "      <td>1.3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3455</td>\n",
       "      <td>115.885</td>\n",
       "      <td>-31.9384</td>\n",
       "      <td>2</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>140.916672</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>234.066666</td>\n",
       "      <td>24.546669</td>\n",
       "      <td>13.283335</td>\n",
       "      <td>1.3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3456</td>\n",
       "      <td>115.883</td>\n",
       "      <td>-31.9403</td>\n",
       "      <td>3</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>140.916672</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>234.066666</td>\n",
       "      <td>24.546669</td>\n",
       "      <td>13.283335</td>\n",
       "      <td>1.3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3457</td>\n",
       "      <td>115.858</td>\n",
       "      <td>-32.0463</td>\n",
       "      <td>4</td>\n",
       "      <td>48.700001</td>\n",
       "      <td>139.833328</td>\n",
       "      <td>53.833332</td>\n",
       "      <td>233.683334</td>\n",
       "      <td>24.253334</td>\n",
       "      <td>13.290004</td>\n",
       "      <td>1.3510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  decimalLongitude  decimalLatitude  key   aet_mean    pet_mean  \\\n",
       "0  3453           115.886         -31.9363    0  47.099998  140.916672   \n",
       "1  3454           115.887         -31.9365    1  47.099998  140.916672   \n",
       "2  3455           115.885         -31.9384    2  47.099998  140.916672   \n",
       "3  3456           115.883         -31.9403    3  47.099998  140.916672   \n",
       "4  3457           115.858         -32.0463    4  48.700001  139.833328   \n",
       "\n",
       "    ppt_mean   srad_mean  tmax_mean  tmin_mean  vap_mean  \n",
       "0  51.400002  234.066666  24.546669  13.283335    1.3445  \n",
       "1  51.400002  234.066666  24.546669  13.283335    1.3445  \n",
       "2  51.400002  234.066666  24.546669  13.283335    1.3445  \n",
       "3  51.400002  234.066666  24.546669  13.283335    1.3445  \n",
       "4  53.833332  233.683334  24.253334  13.290004    1.3510  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to use the joining funtion to join climates and region coords\n",
    "def join_frogs(coords, data):\n",
    "    \"\"\"Collects the weather data for each frog location and joins it onto the test coordinates\n",
    "    Arguments:\n",
    "    coords -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    data -- xarray dataarray of features, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    return coords.merge(\n",
    "        (data#.rename('data')\n",
    "            .sel(\n",
    "                x=xr.DataArray(coords.decimalLongitude, dims=\"key\", coords={\"key\": coords.key}), \n",
    "                y=xr.DataArray(coords.decimalLatitude, dims=\"key\", coords={\"key\": coords.key}),\n",
    "                method=\"nearest\"\n",
    "            )\n",
    "            .to_dataframe()\n",
    "            .assign(val = lambda x: x.iloc[:, -1])\n",
    "            [['val']]\n",
    "            .reset_index()\n",
    "            .drop_duplicates()\n",
    "            .pivot(index=\"key\", columns=\"band\", values=\"val\")\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )\n",
    "    \n",
    "region5 = join_frogs(region_coords, weather_data)\n",
    "region5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ec1f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "region5.to_csv('testRegion5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f204e",
   "metadata": {},
   "source": [
    "现在拿到这个数据之后有很多种研究它的方法，因为它可以和很多不同的东西去比较\n",
    "1. 跟我们training set里面这个地区的climate去比较\n",
    "2. 跟test regions的其他地区的climate去比较\n",
    "3. 跟我们目前最好的那次提交里面这个地区比较\n",
    "3. 甚至可以人工判断哪些点不应该有presence，因为我们可以直接找到threshold（i.e.，温度不能超过多少度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3db4bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gbifID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>stateProvince</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "      <th>coordinateUncertaintyInMeters</th>\n",
       "      <th>occurrenceStatus</th>\n",
       "      <th>aet_mean</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>ppt_mean</th>\n",
       "      <th>srad_mean</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmin_mean</th>\n",
       "      <th>vap_mean</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, gbifID, eventDate, stateProvince, decimalLatitude, decimalLongitude, species, coordinateUncertaintyInMeters, occurrenceStatus, aet_mean, pet_mean, ppt_mean, srad_mean, tmax_mean, tmin_mean, vap_mean, year, month, key]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在尝试跟我们training set里面这个地区比较\n",
    "train = pd.read_csv('climate_frog1520_7vars.csv')\n",
    "region5_train = train[(train['decimalLongitude']<= 116.7)] #& (train['decimalLongitude']>=115.7) ]\n",
    "                      #& (train['decimalLatitude']<= -31.5) & (train['decimalLatitude']>=-32.5)]\n",
    "region5_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ce7c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min Long:  135.783  max Long:  153.63\n",
      "min Lat:  -43.426497  max Lat:  -16.250838\n"
     ]
    }
   ],
   "source": [
    "print('min Long: ', train['decimalLongitude'].min(), ' max Long: ', train['decimalLongitude'].max())\n",
    "print('min Lat: ', train['decimalLatitude'].min(), ' max Lat: ', train['decimalLatitude'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8171f",
   "metadata": {},
   "source": [
    "## 所以问题在于我们的training set里面根本就没有涵盖到这个地区的数据❗\n",
    "- 澳大利亚的坐标是：max_lat = -9.9, min_lat = -43.56, min_long = 112, max_long = 154\n",
    "- 五个test regions的坐标是：\n",
    "\n",
    "min_lon1, min_lat1 = (144.8, -38.5)  \n",
    "max_lon1, max_lat1 = (145.8, -37.5)  \n",
    "bbox1 = (min_lon1, min_lat1, max_lon1, max_lat1)\n",
    "\n",
    "min_lon2, min_lat2 = (150.7, -33.5) \n",
    "max_lon2, max_lat2 = (151.7, -32.5) \n",
    "bbox2 = (min_lon2, min_lat2, max_lon2, max_lat2)\n",
    "\n",
    "min_lon3, min_lat3 = (152.6, -29.0)  \n",
    "max_lon3, max_lat3 = (153.6, -28.0) \n",
    "bbox3 = (min_lon3, min_lat3, max_lon3, max_lat3)\n",
    "\n",
    "min_lon4, min_lat4 = (145.0, -17.7) \n",
    "max_lon4, max_lat4 = (146.0, -16.7)  \n",
    "bbox4 = (min_lon4, min_lat4, max_lon4, max_lat4)\n",
    "\n",
    "min_lon5, min_lat5 = (115.7, -32.5)  \n",
    "max_lon5, max_lat5 = (116.7, -31.5) \n",
    "bbox5 = (min_lon5, min_lat5, max_lon5, max_lat5)\n",
    "\n",
    "- 现在需要检查：\n",
    "    1. 用五个filter，看一下我们的training set有没有漏掉别的区域？\n",
    "    2. 在这五个test region里，还有哪些区域training sample太少，或者class imbalance的？\n",
    "    3. 我们是在哪一步漏掉它们的？是减少uncertaintyMeters的时候？drop years的时候？还是class_balance的时候？\n",
    "- 如果检查出来很严重（i.e.本来有数据被我们删掉了，或者这个region的天气其实跟其他test regions的天气相比不是特别极端），那么就必须重新整理training set，重新做grid search去tune params\n",
    "- 如果检查出来不严重（i.e.本来也就几个data pts，删掉的都是uncertainty特比高，或者直接用人工判断就能解决这个regions不该有的问题），那么可以考虑不用重新做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0422736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>key</th>\n",
       "      <th>aet_mean</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>ppt_mean</th>\n",
       "      <th>srad_mean</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmin_mean</th>\n",
       "      <th>vap_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3751.500000</td>\n",
       "      <td>115.947188</td>\n",
       "      <td>-31.938912</td>\n",
       "      <td>298.500000</td>\n",
       "      <td>47.160259</td>\n",
       "      <td>138.985641</td>\n",
       "      <td>54.854843</td>\n",
       "      <td>233.986572</td>\n",
       "      <td>24.294550</td>\n",
       "      <td>12.665580</td>\n",
       "      <td>1.306463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>172.772008</td>\n",
       "      <td>0.105253</td>\n",
       "      <td>0.159036</td>\n",
       "      <td>172.772008</td>\n",
       "      <td>2.485145</td>\n",
       "      <td>3.513252</td>\n",
       "      <td>6.707797</td>\n",
       "      <td>0.879288</td>\n",
       "      <td>0.514562</td>\n",
       "      <td>0.838230</td>\n",
       "      <td>0.063692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3453.000000</td>\n",
       "      <td>115.716004</td>\n",
       "      <td>-32.412962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.833332</td>\n",
       "      <td>127.283333</td>\n",
       "      <td>42.416668</td>\n",
       "      <td>230.883331</td>\n",
       "      <td>22.576670</td>\n",
       "      <td>10.203335</td>\n",
       "      <td>1.138667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3602.250000</td>\n",
       "      <td>115.886611</td>\n",
       "      <td>-32.032353</td>\n",
       "      <td>149.250000</td>\n",
       "      <td>45.966667</td>\n",
       "      <td>139.187500</td>\n",
       "      <td>51.033333</td>\n",
       "      <td>233.783340</td>\n",
       "      <td>24.136667</td>\n",
       "      <td>12.428335</td>\n",
       "      <td>1.305833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3751.500000</td>\n",
       "      <td>115.916289</td>\n",
       "      <td>-31.932650</td>\n",
       "      <td>298.500000</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>139.833328</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>234.066666</td>\n",
       "      <td>24.546669</td>\n",
       "      <td>13.060001</td>\n",
       "      <td>1.332167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3900.750000</td>\n",
       "      <td>115.995500</td>\n",
       "      <td>-31.864550</td>\n",
       "      <td>447.750000</td>\n",
       "      <td>48.483334</td>\n",
       "      <td>140.916672</td>\n",
       "      <td>55.566666</td>\n",
       "      <td>234.633331</td>\n",
       "      <td>24.601667</td>\n",
       "      <td>13.283335</td>\n",
       "      <td>1.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4050.000000</td>\n",
       "      <td>116.377369</td>\n",
       "      <td>-31.551600</td>\n",
       "      <td>597.000000</td>\n",
       "      <td>53.683334</td>\n",
       "      <td>142.766663</td>\n",
       "      <td>79.666664</td>\n",
       "      <td>235.850006</td>\n",
       "      <td>24.856668</td>\n",
       "      <td>13.560000</td>\n",
       "      <td>1.387000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  decimalLongitude  decimalLatitude         key    aet_mean  \\\n",
       "count   598.000000        598.000000       598.000000  598.000000  598.000000   \n",
       "mean   3751.500000        115.947188       -31.938912  298.500000   47.160259   \n",
       "std     172.772008          0.105253         0.159036  172.772008    2.485145   \n",
       "min    3453.000000        115.716004       -32.412962    0.000000   34.833332   \n",
       "25%    3602.250000        115.886611       -32.032353  149.250000   45.966667   \n",
       "50%    3751.500000        115.916289       -31.932650  298.500000   47.099998   \n",
       "75%    3900.750000        115.995500       -31.864550  447.750000   48.483334   \n",
       "max    4050.000000        116.377369       -31.551600  597.000000   53.683334   \n",
       "\n",
       "         pet_mean    ppt_mean   srad_mean   tmax_mean   tmin_mean    vap_mean  \n",
       "count  598.000000  598.000000  598.000000  598.000000  598.000000  598.000000  \n",
       "mean   138.985641   54.854843  233.986572   24.294550   12.665580    1.306463  \n",
       "std      3.513252    6.707797    0.879288    0.514562    0.838230    0.063692  \n",
       "min    127.283333   42.416668  230.883331   22.576670   10.203335    1.138667  \n",
       "25%    139.187500   51.033333  233.783340   24.136667   12.428335    1.305833  \n",
       "50%    139.833328   51.400002  234.066666   24.546669   13.060001    1.332167  \n",
       "75%    140.916672   55.566666  234.633331   24.601667   13.283335    1.344500  \n",
       "max    142.766663   79.666664  235.850006   24.856668   13.560000    1.387000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region5.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:EY_env]",
   "language": "python",
   "name": "conda-env-EY_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
